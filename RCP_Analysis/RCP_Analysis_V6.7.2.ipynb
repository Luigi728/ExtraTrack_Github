{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "460aa4fd-935e-46b2-8d09-f3d07edb3065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LATITUDE_FORMATTER, LONGITUDE_FORMATTER\n",
    "import cftime\n",
    "import datetime\n",
    "from datetime import date\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import colors\n",
    "from matplotlib import font_manager\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy\n",
    "import pandas\n",
    "from PIL import Image\n",
    "import random\n",
    "from scipy import stats\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d3b5ab-9a6b-4341-b33d-4b3c62ac4ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "Diri = '/glade/u/home/whimkao//ExtraTrack/ExtraTrack_Data/Output_Files_V6/'\n",
    "Output_Diri = '/glade/u/home/whimkao//ExtraTrack/ExtraTrack_Github/RCP_Figs/Output_Files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ee41e7-3935-4bfb-8b91-8288053ef83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open File\n",
    "def Open_File(File):\n",
    "    DF = pandas.read_csv(File)\n",
    "    DF = DF.drop(\"Unnamed: 0\", axis=1)\n",
    "    return (DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b3944dc-fd07-42a7-a849-fb5dee781245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Each File\n",
    "def Files_Open(Model, Diri):\n",
    "    Data_DF = Open_File(Diri+Model+'_Data_SubsetC_Output_V6.csv')\n",
    "    ET_DF = Open_File(Diri+Model+'_ET_SubsetC_Output_V6.csv')\n",
    "    Codes_DF = Open_File(Diri+Model+'_Codes_Output_V6.csv')\n",
    "    Time, Begin_Time, Compl_Time, Peak_Time = [], [], [], []\n",
    "# Edit Time Format\n",
    "    for i in range(len(Data_DF)):\n",
    "        Time.append(Datetime(Data_DF[\"Time(Z)\"][i]))\n",
    "    for j in range(len(ET_DF)):\n",
    "        Begin_Time.append(Datetime(ET_DF[\"ET Begin Time\"][j]))\n",
    "        Compl_Time.append(Datetime(ET_DF[\"ET Complete Time\"][j]))\n",
    "        Peak_Time.append(Datetime(ET_DF[\"Peak Time\"][j]))\n",
    "    Data_DF[\"Time(Z)\"] = Time\n",
    "    ET_DF[\"ET Begin Time\"] = Begin_Time\n",
    "    ET_DF[\"ET Complete Time\"] = Compl_Time\n",
    "    ET_DF[\"Peak Time\"] = Peak_Time\n",
    "    return (Data_DF, ET_DF, Codes_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc1c85a4-d03e-4da1-9b3b-56d94ee801b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Datetime(Time):\n",
    "    New_Time = datetime.datetime.strptime(Time, '%Y-%m-%d %H:%M:%S')\n",
    "    return (New_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2c8177-0000-4e92-b2f6-35733f1293bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a Specific Storm Within the DataFrame\n",
    "def Find_Storm(DF, Code):\n",
    "    DF_Storm = DF[DF[\"Code\"] == Code].reset_index()\n",
    "    return (DF_Storm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41193dbd-36f3-4bcf-b7b0-b9b2f537ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bins\n",
    "def Create_Bins(Min, Max, Bin_Width):\n",
    "    Bins = numpy.arange(Min, Max+Bin_Width, Bin_Width)\n",
    "    return (Bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f1253f9-e844-448b-97cf-5b0f8df3da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Control_Data, Control_ET, Control_Codes = Files_Open(\"Control\", Diri)\n",
    "RCP45_Data, RCP45_ET, RCP45_Codes = Files_Open(\"RCP45\", Diri)\n",
    "RCP85_Data, RCP85_ET, RCP85_Codes = Files_Open(\"RCP85\", Diri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "423247d4-a1ba-4ba9-accc-e8d13bf956a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Find Distance Between Two Points\n",
    "def Find_Distance(y1, y2, x1, x2):\n",
    "    Start_Lat = y1 * numpy.pi / 180\n",
    "    End_Lat = y2 * numpy.pi / 180\n",
    "    Start_Lon = x1 * numpy.pi / 180\n",
    "    End_Lon = x2 * numpy.pi / 180\n",
    "    Lat_Diff = End_Lat - Start_Lat\n",
    "    Lon_Diff = End_Lon - Start_Lon\n",
    "    Earth_Rad = 6378\n",
    "    Distance = 2 * Earth_Rad * numpy.sqrt((numpy.sin(Lat_Diff/2))**2 + \\\n",
    "    numpy.cos(Start_Lat) * numpy.cos(End_Lat) * (numpy.sin(Lon_Diff/2))**2)\n",
    "    return (Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7c6e45b-260d-495c-ae18-0508099ccf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Calculate Gridbox Size\n",
    "def Grid_Size(Grid_Count):\n",
    "    Gridbox = (0.3 * 111.32) ** 2\n",
    "    Area = Grid_Count * Gridbox\n",
    "    return (Area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a77fde-a978-455f-93ab-159f69716a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3639c8b-30fe-4b7b-b933-19fbf9b2a166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2180ad-fcee-40c9-a1e2-1178685d70ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e66d51f8-9bf3-417d-a754-5f0d4d8b0adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Function to Open Storm Composite Files\n",
    "def Composite_File(File):\n",
    "    Diri = '/glade/campaign/univ/upsu0032/Hyperion_ET/composites/'\n",
    "    Compo_File = xr.open_dataset(Diri + File)\n",
    "    return (Compo_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eb4a2e7-35ec-4503-b78c-c05af2834e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Storm Composite Files\n",
    "Control_A_Compo_nc = Composite_File('composite_h3_CHEY.VR28.NATL.REF.CAM5.4CLM5.0.dtime900.002.nc')\n",
    "Control_B_Compo_nc = Composite_File('composite_h3_CORI.VR28.NATL.REF.CAM5.4CLM5.0.dtime900.003.nc')\n",
    "Control_C_Compo_nc = Composite_File('composite_h3_CHEY.VR28.NATL.REF.CAM5.4CLM5.0.dtime900.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "071cf1f6-3c72-460c-bd1a-4431352059b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Storm Composite Files\n",
    "RCP45_A_Compo_nc = Composite_File('composite_h3_CHEY.RCP45.VR28.NATL.REF.CAM5.4CLM5.0.dtime900.nc')\n",
    "RCP45_B_Compo_nc = Composite_File('composite_h3_CHEY.RCP45.VR28.NATL.REF.CAM5.4CLM5.0.dtime900.002.nc')\n",
    "RCP45_C_Compo_nc = Composite_File('composite_h3_CHEY.RCP45.VR28.NATL.REF.CAM5.4CLM5.0.dtime900.003.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf489ea8-1ff1-4e5a-9332-9b7ffdb65a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Storm Composite Files\n",
    "RCP85_A_Compo_nc = Composite_File('composite_h3_CHEY.RCP85.VR28.NATL.REF.CAM5.4CLM5.0.dtime900.nc')\n",
    "RCP85_B_Compo_nc = Composite_File('composite_h3_CHEY.RCP85.VR28.NATL.REF.CAM5.4CLM5.0.dtime900.003.nc')\n",
    "RCP85_C_Compo_nc = Composite_File('composite_h3_CHEY.RCP85.VR28.NATL.REF.CAM5.4CLM5.0.dtime900.004.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e7d1a58-5b9b-4c84-9091-0c47d7772704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame With Lat Lon Time Data of the Composite Files\n",
    "def Composite_DF(Compo_nc, ABC):\n",
    "    Snap_Time = pandas.Series(Compo_nc.snap_time)\n",
    "    Snap_Lon = pandas.Series(Compo_nc.snap_lon)\n",
    "    Snap_Lat = pandas.Series(Compo_nc.snap_lat)\n",
    "    Snap_PathID = pandas.Series(Compo_nc.snap_pathid)\n",
    "    Index = numpy.arange(0,len(Snap_Time),1)\n",
    "    ABC_List = []\n",
    "    for m in range(len(Index)):\n",
    "        ABC_List.append(ABC)\n",
    "    Compo_DF = pandas.DataFrame({\"Orig Index\": Index, \"ABC\": ABC_List, \\\n",
    "    \"Time\": Snap_Time, \"Lon\": Snap_Lon, \"Lat\": Snap_Lat, \"PathID\": Snap_PathID})\n",
    "    return (Compo_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30832c8b-8e71-46f5-96ab-38ec7148fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Composite DFs\n",
    "def Combine_Compo_DF(Compo_A, Compo_B, Compo_C):\n",
    "    Compo_DF_A = Composite_DF(Compo_A, \"A\")\n",
    "    Compo_DF_B = Composite_DF(Compo_B, \"B\")\n",
    "    Compo_DF_C = Composite_DF(Compo_C, \"C\")\n",
    "    Compo_DF = pandas.concat([Compo_DF_A, Compo_DF_B, Compo_DF_C]).reset_index()\n",
    "    Compo_DF = Compo_DF.drop(\"index\", axis=1)\n",
    "    return (Compo_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe1f4df3-eb20-4824-9cbe-8844a6c04c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Control_Compo = Combine_Compo_DF(Control_A_Compo_nc, Control_B_Compo_nc, Control_C_Compo_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df8aa1fa-3bfa-4172-8a84-66f16de06f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RCP45_Compo = Combine_Compo_DF(RCP45_A_Compo_nc, RCP45_B_Compo_nc, RCP45_C_Compo_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a463bd4e-5a9e-476b-85b1-591d526cccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RCP85_Compo = Combine_Compo_DF(RCP85_A_Compo_nc, RCP85_B_Compo_nc, RCP85_C_Compo_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0b5c5a-1603-4455-b95e-a7f74a2afd1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9436389a-04da-463e-ac70-72c0385f74f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f121dfc-c90b-4a39-bf1a-2a2939e347f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Year of Data\n",
    "def Reverse_Update_Year(New_Time, Year_Diff):\n",
    "    Year_Orig = New_Time.year + Year_Diff\n",
    "#    print (Year_Orig)\n",
    "    Orig_Time = New_Time.replace(year=Year_Orig)\n",
    "    return (Orig_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45491917-18a9-4114-9f48-32369186c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Function to Find Year Diff\n",
    "def Year_Diff_Find(New_Time):\n",
    "    Years = [1900,1930,1960,2000,2031,2062,2100,2131,2162,2193]\n",
    "    New_Time_Index = -728\n",
    "    for i in range(len(Years)):\n",
    "        if i < 3:\n",
    "            if New_Time.year >= Years[i] and New_Time.year < Years[i+1]:\n",
    "                Year_Diff = 1985 - Years[i]\n",
    "                New_Time_Index = i\n",
    "        elif i < 6:\n",
    "            if New_Time.year >= Years[i] and New_Time.year < Years[i+1]:\n",
    "                Year_Diff = 2070 - Years[i]\n",
    "                New_Time_Index = i\n",
    "        else:\n",
    "            if New_Time.year >= Years[i] and New_Time.year < Years[i+1]:\n",
    "                Year_Diff = 2070 - Years[i]\n",
    "                New_Time_Index = i\n",
    "    if New_Time_Index % 3 == 0:\n",
    "        ABC = \"A\"\n",
    "    elif New_Time_Index % 3 == 1:\n",
    "        ABC = \"B\"\n",
    "    elif New_Time_Index % 3 == 2:\n",
    "        ABC = \"C\"\n",
    "    return (int(Year_Diff), ABC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c470e0c8-2044-4913-bb09-dfcc2f207dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Function to Find Indexes of Composite Data For Selected Storm\n",
    "def Find_Composite_Data(Code, Data_DF, Compo_DF):\n",
    "    DF_Storm = Find_Storm(Data_DF, Code)\n",
    "    Code_List = DF_Storm[\"Code\"]\n",
    "    Name_List = DF_Storm[\"Name\"]\n",
    "    New_Time = DF_Storm[\"Time(Z)\"]\n",
    "    Lat = DF_Storm[\"Lat\"]\n",
    "    Lon = DF_Storm[\"Lon\"]\n",
    "    SLP = DF_Storm[\"SLP(hPa)\"]\n",
    "    Storm_Phase = DF_Storm[\"Storm Phase\"]\n",
    "    Compo_Indexes = numpy.zeros(len(New_Time))\n",
    "    for i in range(len(New_Time)):\n",
    "        Year_Diff, ABC = Year_Diff_Find(New_Time[0])\n",
    "        Orig_Time = Reverse_Update_Year(New_Time[i], Year_Diff)\n",
    "# Find Possible Storms that Occur at the Same Time\n",
    "        Compo_Storm = Compo_DF[(Compo_DF[\"ABC\"] == ABC) & (Compo_DF[\"Time\"] == Orig_Time)].reset_index()\n",
    "# If No Storm Found:\n",
    "        if len(Compo_Storm) == 0:\n",
    "            Compo_Indexes[i] = -728\n",
    "# Storms Found:\n",
    "        else:\n",
    "            Dist_Min = [7428,-728]\n",
    "            for c in range(len(Compo_Storm)):\n",
    "                Dist = Find_Distance(Lat[i], Compo_Storm[\"Lat\"][c], Lon[i], Compo_Storm[\"Lon\"][c])\n",
    "# Find Storm Closest to Storm Center\n",
    "                if Dist < Dist_Min[0]:\n",
    "# At Most 300km of Error in Location Permitted\n",
    "                    if Dist < 300:\n",
    "                        Dist_Min = [Dist, Compo_Storm[\"Orig Index\"][c]]\n",
    "                    else:\n",
    "                        Dist_Min = [Dist, -728]\n",
    "            Compo_Indexes[i] = Dist_Min[1]\n",
    "    DF_Storm_Compo_Init = pandas.DataFrame({\"Code\": Code_List, \"Name\": Name_List, \\\n",
    "    \"Compo Index\": Compo_Indexes, \"Time\": New_Time, \\\n",
    "    \"Lon\": Lon, \"Lat\": Lat, \"SLP\": SLP, \"Storm Phase\": Storm_Phase})\n",
    "# Remove Datapoints With Missing Compo Index\n",
    "    DF_Storm_Compo = DF_Storm_Compo_Init[DF_Storm_Compo_Init[\"Compo Index\"] >= 0].reset_index()\n",
    "    DF_Storm_Compo = DF_Storm_Compo.drop(\"index\", axis=1)\n",
    "    return (DF_Storm_Compo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c10f7-5b7f-4d25-b2c5-2bdcf3a7c09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a53afe-f516-47cb-83d4-ebc148a52766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d353bb-a1a1-4084-91a5-3dfe3314cd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f315874-3a37-43f7-85b7-ef6c7cfd7604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Windspeed_850hPa(Compo_nc, Compo_Index):\n",
    "    U850 = numpy.array(Compo_nc.snap_U850[int(Compo_Index)])\n",
    "    V850 = numpy.array(Compo_nc.snap_V850[int(Compo_Index)])\n",
    "    Snap_850 = numpy.sqrt(U850 **2 + V850 **2)\n",
    "    return (Snap_850)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdcf167b-6aaa-4693-8c06-e20be5fbad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Precip Rate From Compo File\n",
    "def Precip_Rate(Compo_nc, Compo_Index):\n",
    "    Precip_ms = numpy.array(Compo_nc.snap_PRECT[int(Compo_Index)])\n",
    "    Precip_mmhr = Precip_ms * 3600 * 1000\n",
    "    return (Precip_mmhr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ee0848c-96d7-433f-9c28-150a0332f3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Precipitable Water From Compo File\n",
    "def Precip_Water(Compo_nc, Compo_Index):\n",
    "    Precipitable_Water = numpy.array(Compo_nc.snap_TMQ[int(Compo_Index)])\n",
    "    return (Precipitable_Water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e551b30-b74a-4994-8d30-dd1977aad751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Outgoing Longwave Radiation and Cloud Top Temperature From Compo File\n",
    "def Cloud_Temp(Compo_nc, Compo_Index):\n",
    "    Outgoing_Longwave = numpy.array(Compo_nc.snap_FLUT[int(Compo_Index)])\n",
    "    Sigma = 5.67 * 10**-8\n",
    "    Cloud_Temp_K = (Outgoing_Longwave / (0.95 * Sigma)) ** 0.25\n",
    "    Cloud_Temp_C = Cloud_Temp_K - 273.15\n",
    "    return (Cloud_Temp_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "195a00be-33a8-407e-afef-f806a1ac3bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Surface Temperature From Compo File\n",
    "def Temp_Surface(Compo_nc, Compo_Index):\n",
    "    Temp_K = numpy.array(Compo_nc.snap_TS[int(Compo_Index)])\n",
    "    Temp_C = Temp_K - 273.15\n",
    "    return (Temp_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70921a4b-aaf3-4590-accb-caec6723c6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 850hPa Temperature From Compo File\n",
    "def Temp_850hPa(Compo_nc, Compo_Index):\n",
    "    Temp_K = numpy.array(Compo_nc.snap_T850[int(Compo_Index)])\n",
    "    Temp_C = Temp_K - 273.15\n",
    "    return (Temp_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d972939-ac18-43de-91e2-cf5d66f64059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 500hPa Temperature From Compo File\n",
    "def Temp_500hPa(Compo_nc, Compo_Index):\n",
    "    Temp_K = numpy.array(Compo_nc.snap_T500[int(Compo_Index)])\n",
    "    Temp_C = Temp_K - 273.15\n",
    "    return (Temp_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfb12f34-cd1e-4370-9752-df0354cf152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 200hPa Temperature From Compo File\n",
    "def Temp_200hPa(Compo_nc, Compo_Index):\n",
    "    Temp_K = numpy.array(Compo_nc.snap_T200[int(Compo_Index)])\n",
    "    Temp_C = Temp_K - 273.15\n",
    "    return (Temp_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29905ec3-4cbd-4d69-9740-efb847741d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 500hPa Vertical Velocity From Compo File\n",
    "def Omega_500hPa(Compo_nc, Compo_Index):\n",
    "    Vert_Velo = numpy.array(Compo_nc.snap_OMEGA500[int(Compo_Index)])\n",
    "    return (Vert_Velo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16f74413-1b76-44f8-bba2-5ca3add198c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 200hPa Zonal Winds From Compo File\n",
    "def U_200hPa(Compo_nc, Compo_Index):\n",
    "    Zonal_Wind = numpy.array(Compo_nc.snap_U200[int(Compo_Index)])\n",
    "    return (Zonal_Wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5ac6bc-5757-46fb-9394-37356badf05e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d78c466-b54b-4e7f-a693-d8547301f5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6050bb47-ab34-4ec9-b2f6-688c0a7d7e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e87960f4-da82-4d0e-80b3-e570f7eea8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 850hPa Max Windspeed and Wind Field Size at Each 6 Hourly Data Point\n",
    "def Wind_Field_Find(DF_Storm_Compo, Compo_nc):\n",
    "    Compo_Index = DF_Storm_Compo[\"Compo Index\"]\n",
    "    Time_List = DF_Storm_Compo[\"Time\"]\n",
    "    SLP = DF_Storm_Compo[\"SLP\"]\n",
    "#\n",
    "# Create Array to Store Data\n",
    "    Wind_Field_Info = numpy.zeros((6,len(Compo_Index)))\n",
    "    Wind_Field_Info[0] = SLP\n",
    "#\n",
    "# At Each 6 Hourly Data Point\n",
    "    for k in range(len(Compo_Index)):\n",
    "# Find 850hPa Windspeed Snap From Compo_nc\n",
    "        Snap_850 = Windspeed_850hPa(Compo_nc, Compo_Index[k])\n",
    "# Find Maximum 850hPa Windspeed\n",
    "        Windspeed_850 = numpy.max(Snap_850)\n",
    "        Wind_Field_Info[1][k] = Windspeed_850\n",
    "# Count Number of Data Points With Windspeed Above 13,18,25,33m/s\n",
    "        Snap_Sort = numpy.sort(Snap_850.ravel())\n",
    "        Count_13 = len(Snap_Sort[Snap_Sort >= 13])\n",
    "        Count_18 = len(Snap_Sort[Snap_Sort >= 18])\n",
    "        Count_25 = len(Snap_Sort[Snap_Sort >= 25])\n",
    "        Count_33 = len(Snap_Sort[Snap_Sort >= 33])\n",
    "        Wind_Field_Info[2][k] = Grid_Size(Count_13) * 10**-3\n",
    "        Wind_Field_Info[3][k] = Grid_Size(Count_18) * 10**-3\n",
    "        Wind_Field_Info[4][k] = Grid_Size(Count_25) * 10**-3\n",
    "        Wind_Field_Info[5][k] = Grid_Size(Count_33) * 10**-3\n",
    "#\n",
    "# Add Wind Field Info Into DF Storm Compo\n",
    "    DF_Storm_Compo[\"850hPa Winds\"] = Wind_Field_Info[1]\n",
    "    DF_Storm_Compo[\"13m/s\"] = Wind_Field_Info[2]\n",
    "    DF_Storm_Compo[\"18m/s\"] = Wind_Field_Info[3]\n",
    "    DF_Storm_Compo[\"25m/s\"] = Wind_Field_Info[4]\n",
    "    DF_Storm_Compo[\"33m/s\"] = Wind_Field_Info[5]\n",
    "    return (DF_Storm_Compo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b39e3359-7644-438f-897e-498ec05f7c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Max Precip and Total Precip Over Area\n",
    "def Precip_Field_Find(DF_Storm_Compo, Compo_nc):\n",
    "    Compo_Index = DF_Storm_Compo[\"Compo Index\"]\n",
    "    Time_List = DF_Storm_Compo[\"Time\"]\n",
    "#\n",
    "# Create Array to Store Data\n",
    "    Precip_Field_Info = numpy.zeros((7,len(Compo_Index)))\n",
    "#\n",
    "# At Each 6 Hourly Data Point\n",
    "    for k in range(len(Compo_Index)):\n",
    "# Find Precip Snap From Compo_nc\n",
    "        Snap_Precip = Precip_Rate(Compo_nc, Compo_Index[k])\n",
    "# Find Maximum Precip Rate\n",
    "        Max_Precip = numpy.max(Snap_Precip)\n",
    "        Precip_Field_Info[0][k] = Max_Precip\n",
    "# Find Total Areal Precip\n",
    "        Snap_Sort = numpy.sort(Snap_Precip.ravel())\n",
    "        Areal_Precip_Total = numpy.sum(Snap_Sort)\n",
    "        Precip_Field_Info[1][k] = Areal_Precip_Total\n",
    "# Count Number of Data Points With Precip Rate Above 1, 5, 10mm/hr\n",
    "        Count_1 = len(Snap_Sort[Snap_Sort >= 1])\n",
    "        Count_5 = len(Snap_Sort[Snap_Sort >= 5])\n",
    "        Count_10 = len(Snap_Sort[Snap_Sort >= 10])\n",
    "        Precip_Field_Info[2][k] = Grid_Size(Count_1) * 10**-3\n",
    "        Precip_Field_Info[3][k] = Grid_Size(Count_5) * 10**-3\n",
    "        Precip_Field_Info[4][k] = Grid_Size(Count_10) * 10**-3\n",
    "#\n",
    "# Find Precipitable Water Snap From Compo_nc\n",
    "        Snap_Precip_Water = Precip_Water(Compo_nc, Compo_Index[k])\n",
    "# Find Maximum Precipitable Water\n",
    "        Max_Precip_Water = numpy.max(Snap_Precip_Water)\n",
    "        Precip_Field_Info[5][k] = Max_Precip_Water\n",
    "# Find Areal Precipitable Water Total\n",
    "        Precip_Water_Total = numpy.sum(Snap_Precip_Water.ravel())\n",
    "        Precip_Field_Info[6][k] = Grid_Size(Precip_Water_Total) * 10**-6\n",
    "# \n",
    "# Add Precip Field Info Into DF Storm Compo\n",
    "    DF_Storm_Compo[\"Max Precip Rate\"] = Precip_Field_Info[0]\n",
    "    DF_Storm_Compo[\"Total Areal Precip\"] = Precip_Field_Info[1]\n",
    "    DF_Storm_Compo[\"1mm/hr\"] = Precip_Field_Info[2]\n",
    "    DF_Storm_Compo[\"5mm/hr\"] = Precip_Field_Info[3]\n",
    "    DF_Storm_Compo[\"10mm/hr\"] = Precip_Field_Info[4]\n",
    "    DF_Storm_Compo[\"Max Precip Water\"] = Precip_Field_Info[5]\n",
    "    DF_Storm_Compo[\"Total Precip Water\"] = Precip_Field_Info[6]\n",
    "    return (DF_Storm_Compo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8926b718-c995-4817-af00-894a57830f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Temperature Variables\n",
    "def Temp_Vars_Find(DF_Storm_Compo, Compo_nc):\n",
    "    Compo_Index = DF_Storm_Compo[\"Compo Index\"]\n",
    "#\n",
    "# Create Array to Store Data\n",
    "    Temp_Field_Info = numpy.zeros((8,len(Compo_Index)))\n",
    "#\n",
    "# At Each 6 Hourly Data Point\n",
    "    for k in range(len(Compo_Index)):\n",
    "# Find Each Variable From Compo_nc\n",
    "        Snap_Temp_Cloud = Cloud_Temp(Compo_nc, Compo_Index[k])\n",
    "        Snap_Temp_Sfc = Temp_Surface(Compo_nc, Compo_Index[k])\n",
    "        Snap_Temp_850hPa = Temp_850hPa(Compo_nc, Compo_Index[k])\n",
    "        Snap_Temp_500hPa = Temp_500hPa(Compo_nc, Compo_Index[k])\n",
    "        Snap_Temp_200hPa = Temp_200hPa(Compo_nc, Compo_Index[k])\n",
    "        Snap_Omega_500hPa = Omega_500hPa(Compo_nc, Compo_Index[k])\n",
    "        Snap_U_200hPa = U_200hPa(Compo_nc, Compo_Index[k])\n",
    "#\n",
    "# Find Minimum Cloud Top Temperature\n",
    "        Min_Temp_Cloud = numpy.min(Snap_Temp_Cloud)\n",
    "# Find Mean Surface, 850hPa, 500hPa, 200hPa Temperatures Within 1 Lat/Lon of Storm Center\n",
    "        Mean_Temp_Sfc = numpy.mean(Snap_Temp_Sfc[17:23,17:23])\n",
    "        Mean_Temp_850hPa = numpy.mean(Snap_Temp_850hPa[17:23,17:23])\n",
    "        Mean_Temp_500hPa = numpy.mean(Snap_Temp_500hPa[17:23,17:23])\n",
    "        Mean_Temp_200hPa = numpy.mean(Snap_Temp_200hPa[17:23,17:23])\n",
    "        Mean_U_200hPa = numpy.mean(Snap_U_200hPa[17:23,17:23])\n",
    "# Find Maximum Rising and Sinking Vertical Velocity\n",
    "        Min_Omega = numpy.min(Snap_Omega_500hPa) * -1\n",
    "        Max_Omega = numpy.max(Snap_Omega_500hPa)\n",
    "#\n",
    "# Add To Array\n",
    "        Temp_Field_Info[0][k] = Min_Temp_Cloud\n",
    "        Temp_Field_Info[1][k] = Mean_Temp_Sfc\n",
    "        Temp_Field_Info[2][k] = Mean_Temp_850hPa\n",
    "        Temp_Field_Info[3][k] = Mean_Temp_500hPa\n",
    "        Temp_Field_Info[4][k] = Mean_Temp_200hPa\n",
    "        Temp_Field_Info[5][k] = Mean_U_200hPa\n",
    "        Temp_Field_Info[6][k] = Min_Omega\n",
    "        Temp_Field_Info[7][k] = Max_Omega\n",
    "#\n",
    "# Add To DF Storm Compo\n",
    "    DF_Storm_Compo[\"Min Cloud Temp\"] = Temp_Field_Info[0]\n",
    "    DF_Storm_Compo[\"Sfc Temp\"] = Temp_Field_Info[1]\n",
    "    DF_Storm_Compo[\"850hPa Temp\"] = Temp_Field_Info[2]\n",
    "    DF_Storm_Compo[\"500hPa Temp\"] = Temp_Field_Info[3]\n",
    "    DF_Storm_Compo[\"200hPa Temp\"] = Temp_Field_Info[4]\n",
    "    DF_Storm_Compo[\"200hPa U\"] = Temp_Field_Info[5]\n",
    "    DF_Storm_Compo[\"Max Rising\"] = Temp_Field_Info[6]\n",
    "    DF_Storm_Compo[\"Max Sinking\"] = Temp_Field_Info[7]\n",
    "    return (DF_Storm_Compo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf51eb-b413-40ee-a377-2de4afc1bc15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0755da6-02f0-45d3-a03b-2c77b5632499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bac8b32-ce38-4e9e-86d6-046f95ac0c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "861633ab-4902-468b-a249-99aa95d10b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create New Data DF\n",
    "def DF_Data_Compo(Data_DF, ET_DF, Compo_DF, Compo_nc_A, Compo_nc_B, Compo_nc_C):\n",
    "    Code_List = ET_DF[\"Code\"]\n",
    "    ABC_List = ET_DF[\"ABC\"]\n",
    "# Loop Over Each Storm in Dataset\n",
    "    for n in range(len(Code_List)):\n",
    "        DF_Storm_Compo = Find_Composite_Data(Code_List[n], Data_DF, Compo_DF)\n",
    "# Find Which Compo nc To Use\n",
    "        if ABC_List[n] == \"A\":\n",
    "            Compo_nc = Compo_nc_A\n",
    "        elif ABC_List[n] == \"B\":\n",
    "            Compo_nc = Compo_nc_B\n",
    "        elif ABC_List[n] == \"C\":\n",
    "            Compo_nc = Compo_nc_C\n",
    "# Apply Functions For Finding Wind Field and Precip Field\n",
    "        DF_Storm_Compo = Wind_Field_Find(DF_Storm_Compo, Compo_nc)\n",
    "        DF_Storm_Compo = Precip_Field_Find(DF_Storm_Compo, Compo_nc)\n",
    "        DF_Storm_Compo = Temp_Vars_Find(DF_Storm_Compo, Compo_nc)\n",
    "# Only Keep Storms With Complete ET Data\n",
    "        if len(DF_Storm_Compo) > 0:\n",
    "            if DF_Storm_Compo[\"Storm Phase\"][len(DF_Storm_Compo)-1] == \"Extratropical\":\n",
    "# Combine DF Storm Compos\n",
    "                try:\n",
    "                    Data_Compo = pandas.concat([Data_Compo, DF_Storm_Compo])\n",
    "                except:\n",
    "                    Data_Compo = DF_Storm_Compo.copy()\n",
    "    Data_Compo_Final = Data_Compo.reset_index().drop(\"index\", axis=1)\n",
    "    return (Data_Compo_Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffe91ec8-9f68-4917-93a0-264e31ae51c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create New ET DF\n",
    "def DF_ET_Compo(Data_Compo, ET_DF, Compo_DF, Compo_nc_A, Compo_nc_B, Compo_nc_C):\n",
    "    Code_List = ET_DF[\"Code\"]\n",
    "# Loop Over Each Storm in Dataset\n",
    "    for n in range(len(Code_List)):\n",
    "        ET_Storm = Find_Storm(ET_DF, Code_List[n])\n",
    "        DF_Storm_Compo = Find_Storm(Data_Compo, Code_List[n])\n",
    "# Find ET Begin and ET Complete Time\n",
    "        Trop_Peak_Time = ET_Storm[\"Trop Peak Time\"][0]\n",
    "        Begin_Time = ET_Storm[\"ET Begin Time\"][0]\n",
    "        Compl_Time = ET_Storm[\"ET Complete Time\"][0]\n",
    "        DF_Trop_Peak = DF_Storm_Compo[DF_Storm_Compo[\"Time\"] == Trop_Peak_Time].reset_index()\n",
    "        DF_Begin = DF_Storm_Compo[DF_Storm_Compo[\"Time\"] == Begin_Time].reset_index()\n",
    "        DF_Compl = DF_Storm_Compo[DF_Storm_Compo[\"Time\"] == Compl_Time].reset_index()\n",
    "# Only Keep Storms With Complete ET Data\n",
    "        if len(DF_Storm_Compo) > 0 and len(DF_Trop_Peak) and len(DF_Begin) > 0 and len(DF_Compl) > 0:\n",
    "# Combine ET Storm Compos\n",
    "            ET_Storm_Compo = Find_ET_Compo(Code_List[n], ET_Storm, DF_Trop_Peak, DF_Begin, DF_Compl)\n",
    "            try:\n",
    "                ET_Compo = pandas.concat([ET_Compo, ET_Storm_Compo])\n",
    "            except:\n",
    "                ET_Compo = ET_Storm_Compo.copy()\n",
    "        else:\n",
    "            print (Code_List[n], len(DF_Trop_Peak), len(DF_Begin), len(DF_Compl))\n",
    "    ET_Compo_Final = ET_Compo.reset_index().drop(\"index\", axis=1)\n",
    "    return (ET_Compo_Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c77d2bce-9ec2-46ee-b1cc-3009a6526db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_ET_Compo(Code, ET_Storm, DF_Trop_Peak, DF_Begin, DF_Compl):\n",
    "    ET_Storm_Compo = ET_Storm[[\"Code\", \"Name\", \"Trop Peak Time\", \"ET Begin Time\", \"ET Complete Time\", \\\n",
    "    \"Trop Peak SLP\", \"ET Begin SLP\", \"ET Complete SLP\"]].copy()\n",
    "    Vars = [\"850hPa Winds\", \"13m/s\", \"18m/s\", \"25m/s\", \"33m/s\", \\\n",
    "    \"1mm/hr\", \"5mm/hr\", \"10mm/hr\", \"Max Precip Rate\", \"Max Precip Water\", \"Total Precip Water\", \\\n",
    "    \"Min Cloud Temp\", \"Sfc Temp\", \"850hPa Temp\", \"500hPa Temp\", \"200hPa Temp\", \"200hPa U\", \\\n",
    "    \"Max Rising\", \"Max Sinking\"]\n",
    "    for m in range(len(Vars)):\n",
    "        Var = Vars[m]\n",
    "        Trop_Peak_Var = str(\"Trop Peak \" + Var)\n",
    "        Begin_Var = str(\"ET Begin \" + Var)\n",
    "        Compl_Var = str(\"ET Complete \" + Var)\n",
    "        ET_Storm_Compo[Trop_Peak_Var] = DF_Trop_Peak[Var][0]\n",
    "        ET_Storm_Compo[Begin_Var] = DF_Begin[Var][0]\n",
    "        ET_Storm_Compo[Compl_Var] = DF_Compl[Var][0]\n",
    "    return (ET_Storm_Compo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34debae0-ac90-44b3-bfd4-d06ad94bfa80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b90c9-10f3-4741-883a-206a6158b998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bdf64d-6767-402a-8999-5f753aa1a718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df401e2b-10b1-4b03-ab0b-c55de33537a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Control_Data_Compo = DF_Data_Compo(Control_Data, Control_ET, Control_Compo, \\\n",
    "Control_A_Compo_nc, Control_B_Compo_nc, Control_C_Compo_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9edfdd67-aad1-4ea6-8fba-09a632d3b5ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Control_ET_Compo = DF_ET_Compo(Control_Data_Compo, Control_ET, Control_Compo, \\\n",
    "Control_A_Compo_nc, Control_B_Compo_nc, Control_C_Compo_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5680825-0227-4e9a-8245-299c62c4e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "RCP45_Data_Compo = DF_Data_Compo(RCP45_Data, RCP45_ET, RCP45_Compo, \\\n",
    "RCP45_A_Compo_nc, RCP45_B_Compo_nc, RCP45_C_Compo_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5838767-603f-4865-ab09-63b298baa555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RCP45_ET_Compo = DF_ET_Compo(RCP45_Data_Compo, RCP45_ET, RCP45_Compo, \\\n",
    "RCP45_A_Compo_nc, RCP45_B_Compo_nc, RCP45_C_Compo_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a0ac090-94c2-40b6-bb01-4abf67d77d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RCP85_Data_Compo = DF_Data_Compo(RCP85_Data, RCP85_ET, RCP85_Compo, \\\n",
    "RCP85_A_Compo_nc, RCP85_B_Compo_nc, RCP85_C_Compo_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0db3cdd-e0e1-4838-9d1d-d4f29d67c479",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RCP85_ET_Compo = DF_ET_Compo(RCP85_Data_Compo, RCP85_ET, RCP85_Compo, \\\n",
    "RCP85_A_Compo_nc, RCP85_B_Compo_nc, RCP85_C_Compo_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5d3aa-3c3e-4830-b564-bcb2b1376671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7038d7e4-2564-44b9-93ff-f2d72b47dcab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a0fd8c-2f9e-479b-a453-c525ee4e6efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7d86ff0-baa3-421e-b3bd-050f2a2017de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 25%, Median, 75% Percentiles\n",
    "def Percentile(Array):\n",
    "    Percent_25 = round(numpy.nanpercentile(Array, 25), 1)\n",
    "    Median = round(numpy.nanmedian(Array), 1)\n",
    "    Percent_75 = round(numpy.nanpercentile(Array, 75), 1)\n",
    "    return ([Percent_25, Median, Percent_75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62e0389d-67e4-4dac-83b7-122a90cc23a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Statistical Significance Using KS Test\n",
    "def KS_Test(Control_Array, RCP45_Array, RCP85_Array):\n",
    "    P_Val_RCP45 = round(stats.kstest(Control_Array, RCP45_Array)[1], 3)\n",
    "    P_Val_RCP85 = round(stats.kstest(Control_Array, RCP85_Array)[1], 3)\n",
    "    return (P_Val_RCP45, P_Val_RCP85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9fc2247-56d4-46ca-be5f-921c861e83ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame to Store Percentiles Data\n",
    "def Percentile_DF(Var, Control_Array, RCP45_Array, RCP85_Array):\n",
    "    Control_Percentiles = Percentile(Control_Array)\n",
    "    RCP45_Percentiles = Percentile(RCP45_Array)\n",
    "    RCP85_Percentiles = Percentile(RCP85_Array)\n",
    "    P_Vals = KS_Test(Control_Array, RCP45_Array, RCP85_Array)\n",
    "    Control_Percentiles.append(1.000)\n",
    "    RCP45_Percentiles.append(P_Vals[0])\n",
    "    RCP85_Percentiles.append(P_Vals[1])\n",
    "    DF = pandas.DataFrame({\"Var\": [Var, Var, Var, Var], \"Percentile\": [\"25%\", \"Median\", \"75%\", \"P Val\"], \\\n",
    "    \"Control\": Control_Percentiles, \"RCP4.5\": RCP45_Percentiles, \"RCP8.5\": RCP85_Percentiles})\n",
    "    return (DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc4e7c24-1012-4fc7-83b4-2e184365dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame For Output\n",
    "def Create_Output_DF(Control_ET, RCP45_ET, RCP85_ET, Vars):\n",
    "    for i in range(len(Vars)):\n",
    "        for j in range(3):\n",
    "            if j == 0:\n",
    "                Var = \"Trop Peak \" + Vars[i]\n",
    "            elif j == 1:\n",
    "                Var = \"ET Begin \" + Vars[i]\n",
    "            elif j == 2:\n",
    "                Var = \"ET Complete \" + Vars[i]\n",
    "            DF = Percentile_DF(Var, Control_ET[Var], RCP45_ET[Var], RCP85_ET[Var])\n",
    "            if i == 0 and j == 0:\n",
    "                Output_DF = DF.copy()\n",
    "            else:\n",
    "                Output_DF = pandas.concat([Output_DF, DF])\n",
    "    return (Output_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2d572b8-6109-4ff4-b926-db20d54342fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var</th>\n",
       "      <th>Percentile</th>\n",
       "      <th>Control</th>\n",
       "      <th>RCP4.5</th>\n",
       "      <th>RCP8.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trop Peak 850hPa Winds</td>\n",
       "      <td>25%</td>\n",
       "      <td>46.1</td>\n",
       "      <td>48.200</td>\n",
       "      <td>51.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trop Peak 850hPa Winds</td>\n",
       "      <td>Median</td>\n",
       "      <td>56.6</td>\n",
       "      <td>57.900</td>\n",
       "      <td>59.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trop Peak 850hPa Winds</td>\n",
       "      <td>75%</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.100</td>\n",
       "      <td>67.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trop Peak 850hPa Winds</td>\n",
       "      <td>P Val</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ET Begin 850hPa Winds</td>\n",
       "      <td>25%</td>\n",
       "      <td>38.5</td>\n",
       "      <td>42.700</td>\n",
       "      <td>37.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ET Begin 200hPa U</td>\n",
       "      <td>P Val</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ET Complete 200hPa U</td>\n",
       "      <td>25%</td>\n",
       "      <td>14.2</td>\n",
       "      <td>14.500</td>\n",
       "      <td>13.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ET Complete 200hPa U</td>\n",
       "      <td>Median</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.300</td>\n",
       "      <td>22.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ET Complete 200hPa U</td>\n",
       "      <td>75%</td>\n",
       "      <td>28.6</td>\n",
       "      <td>30.700</td>\n",
       "      <td>28.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ET Complete 200hPa U</td>\n",
       "      <td>P Val</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Var Percentile  Control  RCP4.5  RCP8.5\n",
       "0   Trop Peak 850hPa Winds        25%     46.1  48.200  51.500\n",
       "1   Trop Peak 850hPa Winds     Median     56.6  57.900  59.500\n",
       "2   Trop Peak 850hPa Winds        75%     65.0  68.100  67.800\n",
       "3   Trop Peak 850hPa Winds      P Val      1.0   0.762   0.347\n",
       "0    ET Begin 850hPa Winds        25%     38.5  42.700  37.200\n",
       "..                     ...        ...      ...     ...     ...\n",
       "3        ET Begin 200hPa U      P Val      1.0   0.093   0.484\n",
       "0     ET Complete 200hPa U        25%     14.2  14.500  13.200\n",
       "1     ET Complete 200hPa U     Median     21.4  21.300  22.100\n",
       "2     ET Complete 200hPa U        75%     28.6  30.700  28.200\n",
       "3     ET Complete 200hPa U      P Val      1.0   0.866   0.986\n",
       "\n",
       "[108 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output_DF = Create_Output_DF(Control_ET_Compo, RCP45_ET_Compo, RCP85_ET_Compo, \\\n",
    "[\"850hPa Winds\", \"18m/s\", \"33m/s\", \"10mm/hr\", \"Max Precip Rate\", \"Max Precip Water\", \\\n",
    "\"850hPa Temp\", \"500hPa Temp\", \"200hPa U\"])\n",
    "Output_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24322adf-3936-4a82-a955-3810550d33f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcbe2e1-456c-41f8-b09e-bacf7ee30db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a943d-c331-4d74-9992-4feabfa7beb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b3850b92-b65b-4e1f-88a6-d17d12f8d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output DF to csv File\n",
    "def Output_File(DF, File_Name):\n",
    "    DF.to_csv(Output_Diri+File_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41de4f6b-5061-4093-8609-a0459051c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "Output_File(Output_DF, 'Composites_Table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427d2ccc-1069-4b99-8881-cd59c2652711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c62575-af3b-4b20-a749-be146310129f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2023b",
   "language": "python",
   "name": "npl-2023b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
