{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "460aa4fd-935e-46b2-8d09-f3d07edb3065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LATITUDE_FORMATTER, LONGITUDE_FORMATTER\n",
    "import cftime\n",
    "import datetime\n",
    "from datetime import date\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import colors\n",
    "from matplotlib import font_manager\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy\n",
    "import pandas\n",
    "from PIL import Image\n",
    "import random\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d3b5ab-9a6b-4341-b33d-4b3c62ac4ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "Diri = '/glade/u/home/whimkao//ExtraTrack/ExtraTrack_Data/Output_Files_V6/'\n",
    "Output_Diri = '/glade/u/home/whimkao//ExtraTrack/ExtraTrack_Github/RCP_Figs/Analysis_Figs_V6.7.1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ee41e7-3935-4bfb-8b91-8288053ef83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open File\n",
    "def Open_File(File):\n",
    "    DF = pandas.read_csv(File)\n",
    "    DF = DF.drop(\"Unnamed: 0\", axis=1)\n",
    "    return (DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b3944dc-fd07-42a7-a849-fb5dee781245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Each File\n",
    "def Files_Open(Model, Diri):\n",
    "    Data_DF = Open_File(Diri+Model+'_Data_SubsetD_Output_V6.csv')\n",
    "    ET_DF = Open_File(Diri+Model+'_ET_SubsetD_Output_V6.csv')\n",
    "    Codes_DF = Open_File(Diri+Model+'_Codes_Output_V6.csv')\n",
    "    Time, Begin_Time, Compl_Time, Peak_Time = [], [], [], []\n",
    "# Edit Time Format\n",
    "    for i in range(len(Data_DF)):\n",
    "        Time.append(Datetime(Data_DF[\"Time(Z)\"][i]))\n",
    "    for j in range(len(ET_DF)):\n",
    "        Begin_Time.append(Datetime(ET_DF[\"ET Begin Time\"][j]))\n",
    "        Compl_Time.append(Datetime(ET_DF[\"ET Complete Time\"][j]))\n",
    "        Peak_Time.append(Datetime(ET_DF[\"Peak Time\"][j]))\n",
    "    Data_DF[\"Time(Z)\"] = Time\n",
    "    ET_DF[\"ET Begin Time\"] = Begin_Time\n",
    "    ET_DF[\"ET Complete Time\"] = Compl_Time\n",
    "    ET_DF[\"Peak Time\"] = Peak_Time\n",
    "    return (Data_DF, ET_DF, Codes_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc1c85a4-d03e-4da1-9b3b-56d94ee801b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Datetime(Time):\n",
    "    New_Time = datetime.datetime.strptime(Time, '%Y-%m-%d %H:%M:%S')\n",
    "    return (New_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2c8177-0000-4e92-b2f6-35733f1293bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a Specific Storm Within the DataFrame\n",
    "def Find_Storm(DF, Code):\n",
    "    DF_Storm = DF[DF[\"Code\"] == Code].reset_index()\n",
    "    return (DF_Storm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41193dbd-36f3-4bcf-b7b0-b9b2f537ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bins\n",
    "def Create_Bins(Min, Max, Bin_Width):\n",
    "    Bins = numpy.arange(Min, Max+Bin_Width, Bin_Width)\n",
    "    return (Bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f1253f9-e844-448b-97cf-5b0f8df3da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Control_Data, Control_ET, Control_Codes = Files_Open(\"Control\", Diri)\n",
    "RCP45_Data, RCP45_ET, RCP45_Codes = Files_Open(\"RCP45\", Diri)\n",
    "RCP85_Data, RCP85_ET, RCP85_Codes = Files_Open(\"RCP85\", Diri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "423247d4-a1ba-4ba9-accc-e8d13bf956a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Find Distance Between Two Points\n",
    "def Find_Distance(y1, y2, x1, x2):\n",
    "    Start_Lat = y1 * numpy.pi / 180\n",
    "    End_Lat = y2 * numpy.pi / 180\n",
    "    Start_Lon = x1 * numpy.pi / 180\n",
    "    End_Lon = x2 * numpy.pi / 180\n",
    "    Lat_Diff = End_Lat - Start_Lat\n",
    "    Lon_Diff = End_Lon - Start_Lon\n",
    "    Earth_Rad = 6378\n",
    "    Distance = 2 * Earth_Rad * numpy.sqrt((numpy.sin(Lat_Diff/2))**2 + \\\n",
    "    numpy.cos(Start_Lat) * numpy.cos(End_Lat) * (numpy.sin(Lon_Diff/2))**2)\n",
    "    return (Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a77fde-a978-455f-93ab-159f69716a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3639c8b-30fe-4b7b-b933-19fbf9b2a166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2180ad-fcee-40c9-a1e2-1178685d70ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e66d51f8-9bf3-417d-a754-5f0d4d8b0adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Function to Open Storm Composite Files\n",
    "def Composite_File(File):\n",
    "    Diri = '/glade/campaign/univ/upsu0032/Hyperion_ET/composites/'\n",
    "    Compo_File = xr.open_dataset(Diri + File)\n",
    "    return (Compo_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eb4a2e7-35ec-4503-b78c-c05af2834e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Storm Composite Files\n",
    "Control_A_Compo_nc = Composite_File('composite_h3_CHEY.VR28.NATL.REF.CAM5.4CLM5.0.dtime900.002.nc')\n",
    "Control_B_Compo_nc = Composite_File('composite_h3_CORI.VR28.NATL.REF.CAM5.4CLM5.0.dtime900.003.nc')\n",
    "Control_C_Compo_nc = Composite_File('composite_h3_CHEY.VR28.NATL.REF.CAM5.4CLM5.0.dtime900.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "071cf1f6-3c72-460c-bd1a-4431352059b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Storm Composite Files\n",
    "RCP45_A_Compo_nc = Composite_File('composite_h3_CHEY.RCP45.VR28.NATL.REF.CAM5.4CLM5.0.dtime900.nc')\n",
    "RCP45_B_Compo_nc = Composite_File('composite_h3_CHEY.RCP45.VR28.NATL.REF.CAM5.4CLM5.0.dtime900.002.nc')\n",
    "RCP45_C_Compo_nc = Composite_File('composite_h3_CHEY.RCP45.VR28.NATL.REF.CAM5.4CLM5.0.dtime900.003.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf489ea8-1ff1-4e5a-9332-9b7ffdb65a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Storm Composite Files\n",
    "RCP85_A_Compo_nc = Composite_File('composite_h3_CHEY.RCP85.VR28.NATL.REF.CAM5.4CLM5.0.dtime900.nc')\n",
    "RCP85_B_Compo_nc = Composite_File('composite_h3_CHEY.RCP85.VR28.NATL.REF.CAM5.4CLM5.0.dtime900.003.nc')\n",
    "RCP85_C_Compo_nc = Composite_File('composite_h3_CHEY.RCP85.VR28.NATL.REF.CAM5.4CLM5.0.dtime900.004.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e7d1a58-5b9b-4c84-9091-0c47d7772704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame With Lat Lon Time Data of the Composite Files\n",
    "def Composite_DF(Compo_nc, ABC):\n",
    "    Snap_Time = pandas.Series(Compo_nc.snap_time)\n",
    "    Snap_Lon = pandas.Series(Compo_nc.snap_lon)\n",
    "    Snap_Lat = pandas.Series(Compo_nc.snap_lat)\n",
    "    Snap_PathID = pandas.Series(Compo_nc.snap_pathid)\n",
    "    Index = numpy.arange(0,len(Snap_Time),1)\n",
    "    ABC_List = []\n",
    "    for m in range(len(Index)):\n",
    "        ABC_List.append(ABC)\n",
    "    Compo_DF = pandas.DataFrame({\"Orig Index\": Index, \"ABC\": ABC_List, \\\n",
    "    \"Time\": Snap_Time, \"Lon\": Snap_Lon, \"Lat\": Snap_Lat, \"PathID\": Snap_PathID})\n",
    "    return (Compo_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30832c8b-8e71-46f5-96ab-38ec7148fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Composite DFs\n",
    "def Combine_Compo_DF(Compo_A, Compo_B, Compo_C):\n",
    "    Compo_DF_A = Composite_DF(Compo_A, \"A\")\n",
    "    Compo_DF_B = Composite_DF(Compo_B, \"B\")\n",
    "    Compo_DF_C = Composite_DF(Compo_C, \"C\")\n",
    "    Compo_DF = pandas.concat([Compo_DF_A, Compo_DF_B, Compo_DF_C]).reset_index()\n",
    "    Compo_DF = Compo_DF.drop(\"index\", axis=1)\n",
    "    return (Compo_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe1f4df3-eb20-4824-9cbe-8844a6c04c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Control_Compo = Combine_Compo_DF(Control_A_Compo_nc, Control_B_Compo_nc, Control_C_Compo_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df8aa1fa-3bfa-4172-8a84-66f16de06f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RCP45_Compo = Combine_Compo_DF(RCP45_A_Compo_nc, RCP45_B_Compo_nc, RCP45_C_Compo_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a463bd4e-5a9e-476b-85b1-591d526cccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RCP85_Compo = Combine_Compo_DF(RCP85_A_Compo_nc, RCP85_B_Compo_nc, RCP85_C_Compo_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ed909d-d213-4e3a-af5f-e9ab24043f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0b5c5a-1603-4455-b95e-a7f74a2afd1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9436389a-04da-463e-ac70-72c0385f74f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f121dfc-c90b-4a39-bf1a-2a2939e347f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Year of Data\n",
    "def Reverse_Update_Year(New_Time, Year_Diff):\n",
    "    Year_Orig = New_Time.year + Year_Diff\n",
    "#    print (Year_Orig)\n",
    "    Orig_Time = New_Time.replace(year=Year_Orig)\n",
    "    return (Orig_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45491917-18a9-4114-9f48-32369186c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Function to Find Year Diff\n",
    "def Year_Diff_Find(New_Time):\n",
    "    Years = [1900,1930,1960,2000,2031,2062,2100,2131,2162,2193]\n",
    "    New_Time_Index = -728\n",
    "    for i in range(len(Years)):\n",
    "        if i < 3:\n",
    "            if New_Time.year >= Years[i] and New_Time.year < Years[i+1]:\n",
    "                Year_Diff = 1985 - Years[i]\n",
    "                New_Time_Index = i\n",
    "        elif i < 6:\n",
    "            if New_Time.year >= Years[i] and New_Time.year < Years[i+1]:\n",
    "                Year_Diff = 2070 - Years[i]\n",
    "                New_Time_Index = i\n",
    "        else:\n",
    "            if New_Time.year >= Years[i] and New_Time.year < Years[i+1]:\n",
    "                Year_Diff = 2070 - Years[i]\n",
    "                New_Time_Index = i\n",
    "    if New_Time_Index % 3 == 0:\n",
    "        ABC = \"A\"\n",
    "    elif New_Time_Index % 3 == 1:\n",
    "        ABC = \"B\"\n",
    "    elif New_Time_Index % 3 == 2:\n",
    "        ABC = \"C\"\n",
    "    return (int(Year_Diff), ABC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c470e0c8-2044-4913-bb09-dfcc2f207dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Function to Find Indexes of Composite Data For Selected Storm\n",
    "def Find_Composite_Data(Code, Data_DF, Compo_DF):\n",
    "    DF_Storm = Find_Storm(Data_DF, Code)\n",
    "    Code_List = DF_Storm[\"Code\"]\n",
    "    Name_List = DF_Storm[\"Name\"]\n",
    "    New_Time = DF_Storm[\"Time(Z)\"]\n",
    "    Lat = DF_Storm[\"Lat\"]\n",
    "    Lon = DF_Storm[\"Lon\"]\n",
    "    SLP = DF_Storm[\"SLP(hPa)\"]\n",
    "    Storm_Phase = DF_Storm[\"Storm Phase\"]\n",
    "    Compo_Indexes = numpy.zeros(len(New_Time))\n",
    "    for i in range(len(New_Time)):\n",
    "        Year_Diff, ABC = Year_Diff_Find(New_Time[0])\n",
    "        Orig_Time = Reverse_Update_Year(New_Time[i], Year_Diff)\n",
    "# Find Possible Storms that Occur at the Same Time\n",
    "        Compo_Storm = Compo_DF[(Compo_DF[\"ABC\"] == ABC) & (Compo_DF[\"Time\"] == Orig_Time)].reset_index()\n",
    "# If No Storm Found:\n",
    "        if len(Compo_Storm) == 0:\n",
    "            Compo_Indexes[i] = -728\n",
    "# Storms Found:\n",
    "        else:\n",
    "            Dist_Min = [7428,-728]\n",
    "            for c in range(len(Compo_Storm)):\n",
    "                Dist = Find_Distance(Lat[i], Compo_Storm[\"Lat\"][c], Lon[i], Compo_Storm[\"Lon\"][c])\n",
    "# Find Storm Closest to Storm Center\n",
    "                if Dist < Dist_Min[0]:\n",
    "# At Most 300km of Error in Location Permitted\n",
    "                    if Dist < 300:\n",
    "                        Dist_Min = [Dist, Compo_Storm[\"Orig Index\"][c]]\n",
    "                    else:\n",
    "                        Dist_Min = [Dist, -728]\n",
    "            Compo_Indexes[i] = Dist_Min[1]\n",
    "    DF_Storm_Compo_Init = pandas.DataFrame({\"Code\": Code_List, \"Name\": Name_List, \\\n",
    "    \"Compo Index\": Compo_Indexes, \"Time\": New_Time, \\\n",
    "    \"Lon\": Lon, \"Lat\": Lat, \"SLP\": SLP, \"Storm Phase\": Storm_Phase})\n",
    "# Remove Datapoints With Missing Compo Index\n",
    "    DF_Storm_Compo = DF_Storm_Compo_Init[DF_Storm_Compo_Init[\"Compo Index\"] >= 0].reset_index()\n",
    "    DF_Storm_Compo = DF_Storm_Compo.drop(\"index\", axis=1)\n",
    "    return (DF_Storm_Compo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c10f7-5b7f-4d25-b2c5-2bdcf3a7c09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a53afe-f516-47cb-83d4-ebc148a52766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d353bb-a1a1-4084-91a5-3dfe3314cd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f161001f-e215-45c3-8cdc-9b0c2f6e49f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea66341-ddc5-41b8-9d88-4e964a2abac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d86ff0-baa3-421e-b3bd-050f2a2017de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3850b92-b65b-4e1f-88a6-d17d12f8d7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2023b",
   "language": "python",
   "name": "npl-2023b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
